\section{Analysis}

\subsection{Analytical}

This section will detail the time complexity of each method.\\

\begin{table}[!htbp]
\centering
\begin{tabular}{| l | l |}
	\hline
	\textbf{Method} & \textbf{Time complexity} \\ \hline
	\code{isEmpty()} & O(1) \\ \hline
	\code{contains(Object)} & O(log n) \\ \hline
	\code{hasPredecessor(Object)} & O(log n) \\ \hline
	\code{hasSuccessor(Object)} & O(log n) \\ \hline
	\code{predecessor(Object)} & O(log n) \\ \hline
	\code{successor(Object)} & O(log n) \\ \hline
	\code{min()} & O(1) \\ \hline
	\code{max()} & O(1) \\ \hline
	\code{add(Object)} & O(log n) \\ \hline
	\code{delete(Object)} & O(log n) \\ \hline
	\code{iterator()} & O(1) \\ \hline
	\code{iterator(Object)} & O(log n) \\ \hline
	\code{toString()} & O(n) \\
	\hline
\end{tabular}
\caption{Summary of time complexity of each method.}
\end{table}

Red-black trees have five main properties:
\begin{enumerate}
\item A node is either black or red.
\item The root node is black.
\item Every leaf node is black.
\item A red node has black children.
\item Every path from a node to a leaf descendent contains the same number of black nodes.
\end{enumerate}

First I prove that the following limit on the height of a red-black tree \parencite{clrs}:
\begin{equation*}
h \leq 2\log_2(n+1)
\end{equation*}
\begin{proof}
To begin, we prove that a subtree with root node $n$ has a minimum of $2^{h_b(n)} - 1$ internal nodes (where $b_h(n)$, the 'black-height' of $n$, is the number of black nodes on any path from the node $n$ to any leaf, not including $n$): we do this by induction. For the base case - if the black height of $n$ is zero, then $n$ must be a leaf - and so $2^0 - 1 = 0$ is the number of internal nodes. So it holds for $b_h(n) = 0$. Now we assume that a node $n$ has a positive height and two children (i.e. $n$ is an internal node). Then each child must have a height of $b_h(n)$ or $b_h(n) - 1$, depending on the colour of the child. We can then apply the inductive hypothesis to the children - then each child has $2^{b_h(n) - 1} - 1$ internal nodes. Therefore we can simply sum the number of internal nodes of the two child subtrees to prove the claim - the subtree rooted at $n$ will have at least $(2^{b_h(n) - 1} - 1) + (2^{b_h(n) - 1} - 1) + 1 = 2^{b_h(n)} - 1$ internal nodes.

With the above combined with red-black tree properties, we can complete the proof: if we have a tree of height $h$, then according to the fourth property of red-black trees, at least half of the nodes on any path from the root to a given leaf (not including the root) are black. So $b_h(r) \geq \frac{h}{2}$, where $r$ is the root node of the tree. Then $n \geq 2^{\frac h 2} - 1$, and $h \leq 2\log_2(n + 1)$ follows.
\end{proof}

\subsubsection{\code{isEmpty()}}
This method performs a single null-check of the root node and is independent of the number of elements in the tree. Thus \code{isEmpty()} runs in constant time.

\subsubsection{\code{contains(Object)}}
This method calls the helper method \code{locate(Node)} which is linear in the height of the tree. A proof follows: \\


\subsection{Empirical}

This section gives experimental data on the efficiency of the implementation.

For demonstration of experimental correctness, please refer to the JUnit tests given in the \code{/test/java/DictionaryTest.java} file. JUnit 4.12 was used, and all tests passed at the time of project submission.

Experimental data was obtained by repeatedly running a given method and averaging the result. Each run, the elements are randomly shuffled before being inserted into the dictionary to allow for various internal structures. MATLAB R2014a was used for data visualisation in the figures below.

\subsubsection{Summary}
For \code{add}, \code{delete} and \code{contains}, plot data was averaged over 100 trials. Each trial recorded the number of comparisons made on dictionaries of size ranging from 0 to 100,000.

Plots of the growth of the number of comparisons for adding, deleting and searching are below. Both linear-linear and log-linear graphs are provided to demonstrate the logarithmic growth of the functions.

For the other methods required by the \code{Dictionary} interface, the average number of comparisons made on a 10,000-element dictionary is given in the table below. These results were averaged over 100 trials.

\begin{figure}[!htbpp]
    \centering
    \includegraphics[width=0.49\textwidth]{resources/add}
    \includegraphics[width=0.49\textwidth]{resources/add_log}
    \caption{The number of comparisons made when adding a random distinct element to a dictionary of size n}

\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.49\textwidth]{resources/del}
    \includegraphics[width=0.49\textwidth]{resources/del_log}
    \caption{The number of comparisons made when deleting a random element from a dictionary of size n}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.49\textwidth]{resources/search}
    \includegraphics[width=0.49\textwidth]{resources/search_log}
    \caption{The number of comparisons made when searching for a random element in a dictionary of size n}
\end{figure}

\begin{table}[!htbp]
\centering
\begin{tabular}{| l | l |}
	\hline
	\textbf{Method} & \textbf{Comparisons} \\ \hline
	\code{isEmpty()} & 0.0 \\ \hline
	\code{contains(Object)} & 12.6 \\ \hline
	\code{hasPredecessor(Object)} & 12.6 \\ \hline
	\code{hasSuccessor(Object)} & 12.9 \\ \hline
	\code{predecessor(Object)} & 12.4 \\ \hline
	\code{successor(Object)} & 12.6 \\ \hline
	\code{min()} & 0.0 \\ \hline
	\code{max()} & 0.0 \\ \hline
	\code{add(Object)} & 15.5 \\ \hline
	\code{delete(Object)} & 12.4 \\ \hline
	\code{iterator()} & 0.0 \\ \hline
	\code{iterator(Object)} & 18.4 \\ \hline
	\code{toString()} & 0.0 \\
	\hline
\end{tabular}
\caption{Mean number of comparisons made on a dictionary of 10,000 elements, averaged over 100 trials.}
\end{table}

The above table makes sense: the 'search' methods (\code{contains}, \code{hasPredecessor}, \code{successor}, etc.) take 12 or 13 comparisons. \code{add} takes approximately 2-3 more since it also compares the element with the current tree minimum and maximum. The constant time methods (\code{isEmpty}, \code{min}, \code{max}) need no comparisons. \code{iterator(Object)} uses the most comparisons since when finding the least element greater than the argument, it needs to keep track of the current least element and compare it with each new possibility when traversing down a subtree. \code{toString} also technically uses zero comparisons, while still being the slowest method (having to visit all nodes results in linear time).
