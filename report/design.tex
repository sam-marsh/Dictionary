\section{Design}

\subsection{Decision - Red-Black Tree}

After examining the time complexity for various dictionary implementations, I decided a red-black tree was the most effective implementation for a general-purpose dictionary.

\\

\begin{table}[hp]
\centering
\begin{tabular}{| l | l | l | l |}
\hline
\textbf{Implementation} & \textbf{Search} & \textbf{Insert} & \textbf{Delete} \\ \hline
AVL tree & O(log n) & O(log n) & O(log n) \\ \hline
\color{red} Red-black tree & \color{red} O(log n) & \color{red} O(log n) & \color{red} O(log n) \\ \hline
B-Tree & O(log n) & O(log n) & O(log n) \\ \hline
Splay tree & (a) O(log n) & (a) O(log n) & (a) O(log n) \\ \hline
Skip list & O(n) & O(n) & O(n) \\ \hline
Trie & O(m) & O(m) & O(m) \\ \hline
Stratified tree & O(log log N) & O(log log N) & O(log log N) \\ \hline
\end{tabular}
\\{\tiny{(n = number of elements in data structure, m = length of string, N = size of universe, (a) = amortised)}}\\
\caption{Considered data structures along with their worst-case time complexities.}
\end{table}

When deciding on the optimal data structure, I first ruled out splay tree and skip list, since the skip list worst case time is above the required O(log n) and there are other data structures faster than the splay tree, where amortisation is not required. I then ruled out Trie, although it is extremely fast (independent of size of dictionary), since I aimed to implement a general-purpose dictionary and Trie only holds strings \parencite{trie}.

Initially I implemented basic functionality of a stratified tree \parencite{stratified}, also known as a van Emde Boas tree. The implementation had extremely fast lookup (\code{contains}, \code{max}, \code{min} O(1), and \code{successor}, \code{predecessor}, \code{add}, \code{delete} O(log log N)). However, my primary aim for this project was a \textit{general-purpose} and \textit{unbounded} dictionary. van Emde Boas trees are extremely fast, however the domain is bounded and each element requires an associated integer key. In the end I decided that van Emde Boas trees are too restrictive, and also more suited for a dictionary interface defined using keys and values (like \code{java.util.Map.put(K key, V value)}) and thus a more general purpose and unbounded but less efficient O(log n) solution would be more appropriate for this situation.

Finally, I chose a red-black tree over an AVL tree after considering the usage of the dictionary described in the project: keeping track of users logged in to a web-service. I assume that in most cases, more users log on and off than search for each other, so \textit{insertions and deletions} are more common than \textit{lookups}. Since red-black trees have generally faster inserts and deletions \parencite{clrs} - whereas AVL trees are faster at searches - this would be the most appropriate choice.

\subsection{Implementation}

The majority of my implementation is adapted from the pseudocode in the book 'Introduction to Algorithms: Third Edition' by T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. However, due to the specified requirements of the dictionary, my adaptation of the red-black tree has ended up with various modifications that differ significantly from the CLRS description. In this section, I detail the implementation of the major methods in the \code{RedBlackTree} class.

\subsubsection{Searching}
I considered various options for the \code{contains()} method. My final implementation runs in logarithmic time by using the typical binary search tree search (traversing down the tree). However, I also considered the option of having a separate internal data structure such as a hash table. A hash table would provide \textit{much} faster lookups on average, but unfortunately still has a O(n) worst case. The project specifications require O(log n) worst case, and storing the data in a hash table as well would also essentially double the space requirement. In the end, I decided a basic tree search would suffice for this method.
 
\subsubsection{Successors/predecessors}
This part of the dictionary took several refactorings and was the most challenging part of the project to implement. At first I developed the methods to first locate the node with the given value, and then find the successor of that node using well-known binary search tree methods. Therefore initially, \code{hasPredecessor(Object)} and \code{hasSuccessor(Object)} would take logarithmic time, as they would first check whether the element was contained in the dictionary (O(log n)) and then check whether it was within the bounds of the dictionary (not $\leq$ min or $\geq$ max respectively). However after implementation I realised that it was not required that the argument be contained in the dictionary. Therefore \code{hasPredecessor(Object)} and \code{hasSuccessor(Object)} could be reduced to constant time - since the argument only has to be less than the maximum element to have a successor, and vice versa for predecessor. My final design for \code{successor(Object)} uses a method \code{above(Node)}, which finds the least node strictly greater than the argument.

\subsubsection{Minimum/maximum}
Originally I implemented \code{max()} and \code{min()} to simply call the helper methods \code{minimum(Node)} and \code{maximum(Node)} with the root as the argument. This takes logarithmic time. However, I later modified the class to maintain two extra fields \code{min} and \code{max}. Upon insertion, the current values of \code{min} and \code{max} are compared with the newly inserted element - if the new node is greater than the max or less than the min, the references are updated. This adds a worst-case cost of 2  extra comparisons to the \code{add(Object)} method and reduces \code{min()} and \code{max()} to O(1).

Upon deletion, if the item being deleted is the minimum or the maximum, then the min/max is found by searching the tree again from the root. This is a minor cost when compared to the performance gains from constant time access to the extremum of the dictionary (and doesn't make the time complexity of \code{delete(Object)} any worse).

\subsubsection{Insertion} 
\code{add(Object)} 


\subsubsection{Deletion}

\subsubsection{Iteration}

With the methods above, the iterator was quite simple to implement. The iterator constructor takes in a start node, stores a reference to that start node in an instance variable, and then on each call to \code{next()}, `increments' the node by replacing it with its successor (using \code{successor(Node)}) and returns the previous value.

To implement \code{Iterator\#delete()}, I also stored a reference to the last node returned by \code{next()}. On deletion, I simply call the \code{delete(Node)} method in the enclosing \code{RedBlackTree} class, and then set \code{last} to the \code{nil} sentinel. Setting this field to \code{nil} also works as a check to ensure that the iterator state is valid - if \code{last} is \code{nil}, then we know that either \code{next()} hasn't been called yet or \code{last} has already been deleted. In this case, I throw an \code{IllegalStateException}.

Ensuring the iterator is fail-fast is also implemented fairly simply - in the \code{RedBlackTree} class, a field \code{operations} keeps track of the total number of successful insertions and deletions on the dictionary. In the constructor of \code{TreeIterator}, this number is recorded. Then, each time a method is called on the iterator class, the two numbers are compared - if the number of operations on the tree is not the same as when the iterator was constructed, then a \code{ConcurrentModificationException} is immediately thrown.